{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1364fe-fee7-4289-80b3-001031c2b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278b572fb40e4c1b82a71bc07fc7e1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from llama_pq import LlamaForCausalLM\n",
    "import torch\n",
    "\n",
    "pretrained = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "device = (\n",
    "    torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    pretrained,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=str(device),\n",
    "    _attn_implementation = \"eager\"\n",
    ")\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16c04e1-dd96-4e81-912f-fd2d40902957",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = torch.load('activation.pt')\n",
    "\n",
    "def get_qkv(info, model, layer):\n",
    "    h = 32\n",
    "    group = 4\n",
    "    q_proj = model.model.layers[layer].self_attn.q_proj.weight.T\n",
    "    k_proj = model.model.layers[layer].self_attn.k_proj.weight.T\n",
    "    v_proj = model.model.layers[layer].self_attn.v_proj.weight.T\n",
    "    x = info[0].squeeze(0)\n",
    "    seqlen = info[1]\n",
    "    # print(q_proj.shape, k_proj.shape, v_proj.shape, x.shape, seqlen)\n",
    "    data = x[:seqlen, :]\n",
    "    query = x[seqlen:, :]\n",
    "    q = torch.matmul(query, q_proj).view(query.shape[0], h, -1)\n",
    "    k = torch.matmul(data, k_proj).view(data.shape[0], h//group, -1).repeat_interleave(dim=1, repeats=group)\n",
    "    v = torch.matmul(data, v_proj).view(data.shape[0], h//group, -1).repeat_interleave(dim=1, repeats=group)\n",
    "    # print(q.shape, k.shape, v.shape)\n",
    "    return q.transpose(1, 0), k.transpose(1, 0), v.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73ba15b6-6944-47d5-b728-8506b218351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0, 295, 848,  ..., 714, 711, 710],\n",
      "        [  0, 445, 241,  ..., 714, 762, 834],\n",
      "        [  0, 241, 854,  ..., 759, 762, 834],\n",
      "        ...,\n",
      "        [  0,  71, 346,  ..., 655, 691, 654],\n",
      "        [  0, 430, 230,  ..., 710, 654, 691],\n",
      "        [  0, 104, 231,  ..., 671, 677, 711]], device='cuda:0')\n",
      "efSearch 16 bounded queue True \t   0.001 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 16 bounded queue False \t   0.001 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 32 bounded queue True \t   0.001 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 32 bounded queue False \t   0.001 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 64 bounded queue True \t   0.002 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 64 bounded queue False \t   0.001 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 128 bounded queue True \t   0.003 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 128 bounded queue False \t   0.002 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 256 bounded queue True \t   0.006 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "efSearch 256 bounded queue False \t   0.003 ms per query, R@1 0.9706, missing rate 0.0000\n",
      "hnsw_add_vertices: adding 951 elements on top of 0 (preset_levels=0)\n",
      "  max_level = 2\n",
      "Adding 1 elements at level 2\n",
      "Adding 22 elements at level 1\n",
      "Adding 928 elements at level 0\n",
      "Done in 2.362 ms\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import faiss\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate(index, xq, gt, k):\n",
    "    nq, d = xq.shape\n",
    "    t0 = time.time()\n",
    "    D, I = index.search(xq, k)\n",
    "    t1 = time.time()\n",
    "    # print(D, I)\n",
    "\n",
    "    missing_rate = (I == -1).sum() / float(k * nq)\n",
    "    recall_at_1 = (I == gt[:, :1]).sum() / float(nq)\n",
    "    print(\"\\t %7.3f ms per query, R@1 %.4f, missing rate %.4f\" % (\n",
    "        (t1 - t0) * 1000.0 / nq, recall_at_1, missing_rate))\n",
    "\n",
    "def compute_gt(query, data, k):\n",
    "    mip = torch.matmul(query, data.T)\n",
    "    _, indices = torch.topk(mip, k=data.shape[0], dim=-1)\n",
    "    gt = torch.zeros_like(mip)\n",
    "    gt = gt.scatter(-1, indices, 1)\n",
    "    plt.imshow(gt.float().cpu().detach().numpy())\n",
    "    print(indices)\n",
    "    return indices.cpu().detach().numpy()\n",
    "\n",
    "def anns(query, data, vector, k):\n",
    "    gt = compute_gt(query, data, k)\n",
    "    \n",
    "    query = query.float().cpu().detach().numpy()\n",
    "    data = data.float().cpu().detach().numpy()\n",
    "    index = faiss.IndexHNSWFlat(data.shape[-1], 32)\n",
    "    index.hnsw.efConstruction = 40\n",
    "    index.verbose = True\n",
    "    index.add(data)\n",
    "    for efSearch in 16, 32, 64, 128, 256:\n",
    "        for bounded_queue in [True, False]:\n",
    "            print(\"efSearch\", efSearch, \"bounded queue\", bounded_queue, end=' ')\n",
    "            index.hnsw.search_bounded_queue = bounded_queue\n",
    "            index.hnsw.efSearch = efSearch\n",
    "            evaluate(index, query, gt, k)\n",
    "    return 0, 0, 0\n",
    "    # return recall, count\n",
    "\n",
    "example = 3\n",
    "layer = 10\n",
    "head = 3\n",
    "topk = 10\n",
    "input_info = collection['1'][str(layer)]\n",
    "q, k, v = get_qkv(input_info, model, layer)\n",
    "recall, ratio, error = anns(q[head], k[head], v[head], topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6d05a-40f8-4eb4-979f-3d050530bbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
